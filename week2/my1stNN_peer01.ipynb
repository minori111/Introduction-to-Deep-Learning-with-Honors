{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADSBJREFUeJzt3X+IXfWZx/HPZ7VBTPqHmtkQbNxJNGhE3CkMcaG6dIkJ\nVoqxCtIIJYvSVOgWCxVW9I8V/1GWbYuRpTJdQ+PStVloxSBhq8ZVKUhwIlkTG9e4OqGJ+XFDlBoF\nozPP/jEnZapzz72599x77szzfsEw957nnDkPJ/nMued879yvI0IA8vmLuhsAUA/CDyRF+IGkCD+Q\nFOEHkiL8QFKEH0iK8ANJEX4gqXP7ubPFixfH8PBwP3cJpDIxMaETJ064nXW7Cr/tGyQ9IukcSf8W\nEQ+XrT88PKzx8fFudgmgxOjoaNvrdvyy3/Y5kv5V0jckXSlpg+0rO/15APqrm2v+1ZLejoh3IuK0\npF9JWl9NWwB6rZvwXyzpDzOeHyqW/Rnbm2yP2x5vNBpd7A5AlXp+tz8ixiJiNCJGh4aGer07AG3q\nJvyHJS2b8fwrxTIAc0A34X9V0krby20vkPRtSduraQtAr3U81BcRn9n+B0m/1fRQ35aIeKOyzgD0\nVFfj/BGxQ9KOinoB0Ee8vRdIivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIP\nJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnC\nDyRF+IGkupql1/aEpA8lTUr6LCJGq2gKqML+/fub1q6//vrSbffs2VNaHxoa6qinQdJV+At/FxEn\nKvg5APqIl/1AUt2GPyQ9b3u37U1VNASgP7p92X9tRBy2/ZeSnrP9ZkS8PHOF4pfCJkm65JJLutwd\ngKp0deaPiMPF9+OSnpK0epZ1xiJiNCJG58NNEmC+6Dj8thfa/vKZx5LWSdpXVWMAequbl/1LJD1l\n+8zP+Y+I+K9KugLQcx2HPyLekfTXFfbSUwcOHCitv//++6X11au/cEWDAbdr166mtTVr1vSxk8HE\nUB+QFOEHkiL8QFKEH0iK8ANJEX4gqSr+qm9O2LlzZ2n9zTffLK0z1Dd4IqK0Xja8+9Zbb1XdzpzD\nmR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkkozzr958+bS+rp16/rUCapy6tSp0vpDDz3UtHb33XeX\nbpvhU6c48wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUmnG+ScnJ+tuARW76667Ot521apVFXYyN3Hm\nB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkWo7z294i6ZuSjkfEVcWyCyVtkzQsaULSbRFRPsd1j733\n3nul9cOHD/epE/TLyZMnO9527dq1FXYyN7Vz5v+FpBs+t+xeSTsjYqWkncVzAHNIy/BHxMuSPv8r\ndr2krcXjrZJurrgvAD3W6TX/kog4Ujw+KmlJRf0A6JOub/jF9IRpTSdNs73J9rjt8Uaj0e3uAFSk\n0/Afs71Ukorvx5utGBFjETEaEaMZPhQRmCs6Df92SRuLxxslPV1NOwD6pWX4bT8p6RVJl9s+ZPtO\nSQ9LWmv7gKTri+cA5pCW4/wRsaFJaU3FvXTl2WefLa1//PHHfeoEVfnoo49K63v37u34Z1900UUd\nbztf8A4/ICnCDyRF+IGkCD+QFOEHkiL8QFLz5qO79+3b19X2IyMjFXWCqtx///2l9VZ/xn311Vc3\nrS1YsKCjnuYTzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNS8Gefv1jXXXFN3C3PSJ598UlrfvXt3\n09rY2Fjpttu2beuopzM2b97ctHbeeed19bPnA878QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4/yF\nDz74oLZ9t/q79KmpqdL6Sy+91LT27rvvlm57+vTp0vqjjz5aWp+cnCytL1y4sGlt3bp1pdu2Gov/\n9NNPS+urVq0qrWfHmR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmo5zm97i6RvSjoeEVcVyx6Q9F1J\njWK1+yJiR6+abMf5559fWrddWr/ppptK65dffvlZ99SuV155pbQeEaX1c89t/s+4aNGi0m1bfY7B\nPffcU1q/7rrrSutl8yGUvQdAkpYtW1ZabzWF99DQUGk9u3bO/L+QdMMsy38aESPFV63BB3D2WoY/\nIl6WdLIPvQDoo26u+X9g+3XbW2xfUFlHAPqi0/D/TNIKSSOSjkj6cbMVbW+yPW57vNFoNFsNQJ91\nFP6IOBYRkxExJennklaXrDsWEaMRMcoNGGBwdBR+20tnPP2WpO6myAXQd+0M9T0p6euSFts+JOmf\nJH3d9oikkDQh6Xs97BFAD7QMf0RsmGXx4z3opSsPPvhgaf3SSy8trb/44osVdnN2Vq5cWVq//fbb\nS+uXXXZZ09ry5cs76qkfduwoHyE+evRoaf2KK66osp10eIcfkBThB5Ii/EBShB9IivADSRF+IKk0\nH929cePGruqo3jPPPNPV9nfccUdFneTEmR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkkozzo/555Zb\nbqm7hTmNMz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiAp\nwg8k1fLv+W0vk/SEpCWSQtJYRDxi+0JJ2yQNS5qQdFtEvN+7VpFNRJTWDx48WFpfsWJFle3MO+2c\n+T+T9KOIuFLS30j6vu0rJd0raWdErJS0s3gOYI5oGf6IOBIRrxWPP5S0X9LFktZL2lqstlXSzb1q\nEkD1zuqa3/awpK9K2iVpSUQcKUpHNX1ZAGCOaDv8thdJ+rWkH0bEH2fWYvribNYLNNubbI/bHm80\nGl01C6A6bYXf9pc0HfxfRsRvisXHbC8t6kslHZ9t24gYi4jRiBgdGhqqomcAFWgZftuW9Lik/RHx\nkxml7ZLOTG27UdLT1bcHoFfa+ejur0n6jqS9tvcUy+6T9LCk/7R9p6SDkm7rTYvIavq809zU1FSf\nOpmfWoY/In4nqdm/wppq2wHQL7zDD0iK8ANJEX4gKcIPJEX4gaQIP5AUU3RjznrhhRdK62vWMBJd\nhjM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFOD8GVquP7kZ3OPMDSRF+ICnCDyRF+IGkCD+QFOEH\nkiL8QFKM86M2t956a2n9scce61MnOXHmB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkWo7z214m6QlJ\nSySFpLGIeMT2A5K+K6lRrHpfROzoVaOYf1p9rv7U1FSfOsmpnTf5fCbpRxHxmu0vS9pt+7mi9tOI\n+JfetQegV1qGPyKOSDpSPP7Q9n5JF/e6MQC9dVbX/LaHJX1V0q5i0Q9sv257i+0Lmmyzyfa47fFG\nozHbKgBq0Hb4bS+S9GtJP4yIP0r6maQVkkY0/crgx7NtFxFjETEaEaNDQ0MVtAygCm2F3/aXNB38\nX0bEbyQpIo5FxGRETEn6uaTVvWsTQNVaht+2JT0uaX9E/GTG8qUzVvuWpH3VtwegV9q52/81Sd+R\ntNf2nmLZfZI22B7R9PDfhKTv9aRDAD3Rzt3+30nyLCXG9IE5jHf4AUkRfiApwg8kRfiBpAg/kBTh\nB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHknJE9G9ndkPSwRmLFks60bcGzs6g9jaofUn0\n1qkqe/uriGjr8/L6Gv4v7Nwej4jR2hooMai9DWpfEr11qq7eeNkPJEX4gaTqDv9YzfsvM6i9DWpf\nEr11qpbear3mB1Cfus/8AGpSS/ht32D7f22/bfveOnpoxvaE7b2299ger7mXLbaP2943Y9mFtp+z\nfaD4Pus0aTX19oDtw8Wx22P7xpp6W2b7v23/3vYbtu8ultd67Er6quW49f1lv+1zJL0laa2kQ5Je\nlbQhIn7f10aasD0haTQiah8Ttv23kk5JeiIiriqW/bOkkxHxcPGL84KI+McB6e0BSafqnrm5mFBm\n6cyZpSXdLOnvVeOxK+nrNtVw3Oo486+W9HZEvBMRpyX9StL6GvoYeBHxsqSTn1u8XtLW4vFWTf/n\n6bsmvQ2EiDgSEa8Vjz+UdGZm6VqPXUlftagj/BdL+sOM54c0WFN+h6Tnbe+2vanuZmaxpJg2XZKO\nSlpSZzOzaDlzcz99bmbpgTl2ncx4XTVu+H3RtRExIukbkr5fvLwdSDF9zTZIwzVtzdzcL7PMLP0n\ndR67Tme8rlod4T8sadmM518plg2EiDhcfD8u6SkN3uzDx85Mklp8P15zP38ySDM3zzaztAbg2A3S\njNd1hP9VSSttL7e9QNK3JW2voY8vsL2wuBEj2wslrdPgzT68XdLG4vFGSU/X2MufGZSZm5vNLK2a\nj93AzXgdEX3/knSjpu/4/5+k++vooUlfKyT9T/H1Rt29SXpS0y8DP9X0vZE7JV0kaaekA5Kel3Th\nAPX275L2Snpd00FbWlNv12r6Jf3rkvYUXzfWfexK+qrluPEOPyApbvgBSRF+ICnCDyRF+IGkCD+Q\nFOEHkiL8QFKEH0jq/wF5gg4vl0hTWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb7f68c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[2], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "[5 0 4 ..., 8 4 8]\n",
      "(50000, 10)\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "s = tf.InteractiveSession()\n",
    "n_x = X_train.shape[1] * X_train.shape[2]\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], n_x)\n",
    "print(X_train_flatten.shape)\n",
    "\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], n_x)\n",
    "\n",
    "X_val_flatten = X_val.reshape(X_val.shape[0], n_x)\n",
    "#y_train.reshape(1,50000)\n",
    "one_hot_train = tf.one_hot(indices = y_train, depth = 10, axis = 1)\n",
    "print(y_train)\n",
    "one_hot_val = tf.one_hot(indices = y_val, depth = 10, axis = 1)\n",
    "one_hot_train = s.run(one_hot_train)\n",
    "one_hot_val = s.run(one_hot_val)#use one_hot deal with y_train and y_val\n",
    "print(one_hot_train.shape)\n",
    "print(one_hot_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w1 = tf.Variable(tf.random_normal(shape = [n_x,50],mean = 0, stddev = 0.01),dtype = 'float32')\n",
    "b1 = tf.Variable(tf.random_normal(shape = [50],mean = 0, stddev = 0.01),dtype = 'float32')\n",
    "w2 = tf.Variable(tf.random_normal(shape = [50, 10],mean = 0, stddev = 0.01),dtype = 'float32')\n",
    "b2 = tf.Variable(tf.random_normal(shape = [10],mean = 0, stddev = 0.01),dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_X = tf.placeholder(\"float32\", shape=(None,None), name='input_x')\n",
    "input_y = tf.placeholder(\"float32\", shape=(None,None), name ='input_y')\n",
    "hidden_y = tf.nn.relu((tf.matmul(input_X, w1) + b1))#input and hidden layer\n",
    "predicted_y = tf.nn.softmax(tf.matmul(hidden_y,w2)+b2)#output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "#predicted_y = tf.sigmoid(tf.matmul((tf.matmul(input_X, w1) + b1),w2) + b2) #不能用x_flatten代替input_X\n",
    "print(predicted_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "loss = -tf.reduce_mean(input_y * tf.log(predicted_y + 1e-10) + (1-input_y)* tf.log(1-predicted_y + 1e-10))#将损失函数改成此种形式就不会出现nan\n",
    "#loss = -tf.reduce_mean(input_y * tf.log(predicted_y) + (1-input_y)*tf.log(1-predicted_y))\n",
    "print(loss.shape)\n",
    "#optimizer = tf.train.MomentumOptimizer(0.29,0.9).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01,beta1=0.9,beta2=0.999,epsilon=1e-08,).minimize(loss)#use Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "s.run(optimizer, {input_X:X_train_flatten, input_y:one_hot_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iter 0:0.3028942645\n",
      "loss at iter 10:0.0862055495\n",
      "loss at iter 20:0.0601098835\n",
      "loss at iter 30:0.0490659438\n",
      "loss at iter 40:0.0411876030\n",
      "loss at iter 50:0.0355375819\n",
      "loss at iter 60:0.0315066651\n",
      "loss at iter 70:0.0283373538\n",
      "loss at iter 80:0.0256233141\n",
      "loss at iter 90:0.0232883133\n",
      "loss at iter 100:0.0213501863\n",
      "loss at iter 110:0.0194856711\n",
      "loss at iter 120:0.0178665500\n",
      "loss at iter 130:0.0164213646\n",
      "loss at iter 140:0.0151314354\n",
      "loss at iter 150:0.0139517747\n",
      "loss at iter 160:0.0128833009\n",
      "loss at iter 170:0.0118907942\n",
      "loss at iter 180:0.0110575883\n",
      "loss at iter 190:0.0102737751\n",
      "loss at iter 200:0.0094435867\n",
      "loss at iter 210:0.0087472172\n",
      "loss at iter 220:0.0080603333\n",
      "loss at iter 230:0.0073916456\n",
      "loss at iter 240:0.0068308669\n",
      "loss at iter 250:0.0062221386\n"
     ]
    }
   ],
   "source": [
    "for i in range(260):\n",
    "    s.run(optimizer, {input_X:X_train_flatten, input_y:one_hot_train})\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        loss_i = s.run(loss,{input_X:X_train_flatten, input_y:one_hot_train})\n",
    "        print(\"loss at iter %i:%.10f\" % (i, loss_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.99998927e-01   1.90074363e-15   1.11407257e-06   5.66909684e-08\n",
      "   4.44781840e-18   1.15786786e-12   2.16096530e-10   7.61815194e-11\n",
      "   8.27891792e-13   5.96911276e-09]\n"
     ]
    }
   ],
   "source": [
    "predicted_train = s.run(predicted_y,{input_X:X_train_flatten,input_y:one_hot_train})\n",
    "print(predicted_train[1])#View the predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967\n"
     ]
    }
   ],
   "source": [
    "predicted_val = s.run(predicted_y,{input_X:X_val_flatten,input_y:one_hot_val})\n",
    "correct_prediction = tf.equal(tf.argmax(predicted_val, 1), tf.argmax(one_hot_val, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "accuracy_result = s.run(accuracy, feed_dict={input_X: X_val_flatten})\n",
    "print(accuracy_result) #Accuracy rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
